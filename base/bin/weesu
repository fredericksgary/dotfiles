#!/usr/bin/env bash

# A script for creating and managing records of where
# (presumably large) files are.
#
# Can read a directory and create a JSON file describing
# its contents (including recursing into tarballs and
# zip files), merge JSON files together, and query
# and edit JSON files

function emit-stack-trace {
    local -i x
    local -i stack_frames="${#FUNCNAME[@]}"

    {
        echo "ERROR in ${FUNCNAME[1]}() at ${BASH_SOURCE[1]}:${BASH_LINENO[0]}"

        for (( x=2; x < stack_frames; x++ ))
        do
            echo "    called by ${FUNCNAME[x]}() at ${BASH_SOURCE[x]}:${BASH_LINENO[x - 1]}"
        done
    } >&2
}

function be-strict {
    set -o errexit    # Die on non-0 exit codes other than inside conditions.
    set -o noclobber  # Do not overwrite files without being explicit about it.
    set -o nounset    # Do not allow using unset variables.
    set -o pipefail   # Cause errors in the middle of pipelines to be caught.
    set -o errtrace   # ERR trap works in functions, subshells, etc.

    trap emit-stack-trace ERR
}

be-strict
shopt -s dotglob # so globbing gets hidden things

print_usage_and_exit(){
    cat >&2 <<EOF
    Usage:

    weesu catalog <source-id> <dirname> [--exclude \$JQ_REGEX]
      - writes a json file to stdout
      - if the exclusion regex is given, the following restrictions apply:
        - no observation whose path matches the regex will be output
        - if the path to an otherwise-output tarball with "//"
          appended matches the regex, then none of the contents of the
          tarball will be output
        - if the path to a directory matches (without a trailing "/"), then
          none of its contents will be output
    weesu merge <file1> <file2>
      - writes a json file to stdout
    weesu stale
      - reads json records from stdin and prints
        a summary of blobs that were previously
        seen at a source but not in the latest
        viewing of that source
    weesu histogram
      - reads json records from stdin and prints
        a count of what combinations of sources
        blobs appear in
EOF
    exit 1
}

# Unrolled format:
# "$SHA $SIZE $SOURCE_ID_BASE64 $PATH_BASE64 $AT"

# Converts the line format to the json format, removing any adjacent
# lines that are identical but for the final timestamp (retaining the
# latest timestamp)
rollup(){
    # Might be able to do this all in jq with foreach; no guess
    # whether that'd be faster though; it'd at least avoid moderately
    # long lines
    THIS_SHA=""
    THIS_SIZE=""
    THIS_DOUBLET=""
    THIS_AT=""
    THESE_TRIPLETS=()
    cat - <(echo LAST_LINE) \
        | while read SHA SIZE SOURCE_ID_BASE64 PATH_BASE64 AT; do
        if [[ "$SHA" == "LAST_LINE" ]]; then
            if [[ "$THIS_SHA" != "" ]]; then
                THESE_TRIPLETS+=("$(echo -n "$THIS_DOUBLET $THIS_AT" | base64 -w0)")
                echo "$THIS_SHA $THIS_SIZE $(echo "${THESE_TRIPLETS[*]}")"
            fi
        elif [[ "$SHA" == "$THIS_SHA" ]]; then
            [[ "$SIZE" == "$THIS_SIZE" ]] || \
                {
                    echo "UNEXPECTED SIZE MISMATCH: SHA=$SHA, SIZE1=$SIZE, SIZE2=$THIS_SIZE" >&2
                    exit 1
                }
            NEW_DOUBLET="$SOURCE_ID_BASE64 $PATH_BASE64"
            if [[ "$NEW_DOUBLET" == "$THIS_DOUBLET" ]]; then
                if [[ "$AT" > "$THIS_AT" ]]; then
                    THIS_AT="$AT"
                fi
            else
                THESE_TRIPLETS+=("$(echo -n "$THIS_DOUBLET $THIS_AT" | base64 -w0)")
                THIS_DOUBLET="$NEW_DOUBLET"
                THIS_AT="$AT"
            fi
        else
            if [[ "$THIS_SHA" != "" ]]; then
                THESE_TRIPLETS+=("$(echo -n "$THIS_DOUBLET $THIS_AT" | base64 -w0)")
                echo "$THIS_SHA $THIS_SIZE $(echo "${THESE_TRIPLETS[*]}")"
            fi
            THIS_SHA="$SHA"
            THIS_SIZE="$SIZE"
            THIS_DOUBLET="$SOURCE_ID_BASE64 $PATH_BASE64"
            THIS_AT="$AT"
            THESE_TRIPLETS=()
        fi
    done \
        | jq -cMR '. / " " | .[0] as $SHA | .[1] as $SIZE | .[2:] | map(@base64d | . / " " | {source_id: (.[0] | @base64d), path: (.[1] | @base64d), at:(.[2])}) | {sha256: $SHA, size: ($SIZE | tonumber), seen: .}'
}

# Converts the json format to the line format
unrollup(){
    jq -crM '. as $rec | .seen[] | "\($rec.sha256) \($rec.size) \(.source_id | @base64) \(.path | @base64) \(.at)"'
}

sort_and_rollup(){
    LC_ALL=C sort | rollup
}

_head(){
    local N="$2"
    while [[ "$N" -gt 0 ]]; do
        read VAR;
        N=$((N-1))
        echo "$VAR"
    done
}

all_matching_dirs(){
    local EXCLUSION_REGEX="$1"
    # This is some crazy-go-nuts shell programming where we're just
    # running two processes that are mutually connected by a pair of
    # pipes, just for the sake of implementing a tree walker in bash
    # where the filtering gets done by jq
    #
    # Also there's extra nonsense with base64 because I don't want to
    # worry about all the weird edge cases (mostly whitespace) in
    # passing paths around otherwise.
    local PIPE1=$(mktemp -u)
    mkfifo $PIPE1
    exec 3<>$PIPE1
    local PIPE2=$(mktemp -u)
    mkfifo $PIPE2
    exec 4<>$PIPE2
    local OVERFLOW_DIR=$(mktemp -d)
    local JQ='(if @base64d | test($re;"m") then "N" else "Y" end) as $bool
        | "\($bool) \(.)"'
    jq <&3 >&4 \
        -rR \
        --arg re "$EXCLUSION_REGEX" \
        --unbuffered \
        "$JQ" &
    local JQ_PID=$!

    local WRITTEN=1
    local READ=0
    local NEXT_BUFFER_FILE=0
    local LINES_IN_BUFFER=0
    local BUFFER_FILE_SIZE=50
    echo >&3 # kick it off
    while true; do
        # Is the buffering algorithm here even deterministic? I don't know
        if [[ "$WRITTEN" -gt "$READ" ]] || [[ "$LINES_IN_BUFFER" -gt 0 ]]; then
            if [[ "$WRITTEN" -gt "$READ" ]]; then
                read BOOL PATH64 <&4
                READ=$((READ + 1))
            else
                if [[ $((LINES_IN_BUFFER % BUFFER_FILE_SIZE)) -eq 0 ]]; then
                    local NUM_TO_OPEN=$((NEXT_BUFFER_FILE - (LINES_IN_BUFFER / BUFFER_FILE_SIZE)))
                    if [[ $NUM_TO_OPEN -gt 0 ]]; then
                        exec 5<&-
                        rm $OVERFLOW_DIR/$((NUM_TO_OPEN - 1))
                    fi
                    exec 5<$OVERFLOW_DIR/$NUM_TO_OPEN
                fi
                read BOOL PATH64 <&5
                LINES_IN_BUFFER=$((LINES_IN_BUFFER - 1))
            fi
            if [[ "$BOOL" == "Y" ]]; then
                echo "$PATH64"
                local THE_PATH="$(echo "$PATH64" | base64 -d)"
                pushd "$THE_PATH" >/dev/null
                for DIR in *; do
                    if [[ ! -L "$DIR" && -d "$DIR" ]]; then
                        if [[ "$THE_PATH" == "" ]]; then
                          local NEW_PATH="$DIR"
                        else
                          local NEW_PATH="$THE_PATH/$DIR"
                        fi
                        local B64="$(echo "$NEW_PATH" | base64 -w0)"
                        echo "$B64" >&3
                        WRITTEN=$((WRITTEN+1))
                        if [[ "$WRITTEN" -gt "$((READ + BUFFER_FILE_SIZE))" ]]; then
                            # Why can't I use normal head here? Does it close the FD?
                            _head <&4 -n $BUFFER_FILE_SIZE > $OVERFLOW_DIR/$NEXT_BUFFER_FILE
                            READ=$((READ + BUFFER_FILE_SIZE))
                            NEXT_BUFFER_FILE=$((NEXT_BUFFER_FILE + 1))
                            LINES_IN_BUFFER=$((LINES_IN_BUFFER + BUFFER_FILE_SIZE))
                        fi
                    fi
                done
                popd >/dev/null
            fi
        else
            break
        fi
    done
    exec 3<&-
    exec 4<&-
    # I don't know why the jq doesn't exit itself
    kill $JQ_PID
    wait $JQ_PID 2>/dev/null || true
    rm "$PIPE1"
    rm "$PIPE2"
    rm -rf "$OVERFLOW_DIR"
}

all_matching_files(){
    local EXCLUSION_REGEX="$1"
    local JQ='if @base64d | test($re;"m") then empty else . end'
    while read DIR64; do
        local DIR="$(echo "$DIR64" | base64 -d)"
        pushd "$DIR" >/dev/null
        for FILE in *; do
            if [[ ! -L "$FILE" && -f "$FILE" ]]; then
                if [[ "$DIR" == "" ]]; then
                    local THE_PATH="$FILE"
                else
                    local THE_PATH="$DIR/$FILE"
                fi
                echo "$THE_PATH" | base64 -w0
                echo
                if [[ "$FILE" == *.tgz || "$FILE" == *.tar.gz ]]; then
                    echo "$THE_PATH//" | base64 -w0
                    echo
                fi
            fi
        done
        popd >/dev/null
    done  \
        | jq -rR --arg re "$EXCLUSION_REGEX" "$JQ"
}

read_files(){
    local EXCLUSION_REGEX="$1"
    # at this point everything matches, except perhaps tarball
    # contents
    while read FILE64; do
        local FILE="$(echo "$FILE64" | base64 -d)"
        if [[ "$FILE" == *// ]]; then
            local TARBALL="${FILE::-2}"
            local JQ='if . / " " | .[3] | @base64d | test($re;"m") then empty else . end'
            __WEESU_RECUR__=t \
                           __WEESU_PATH__="$FILE" \
                           tar --to-command="$0" -zxf "$TARBALL" \
                | jq -rR --arg re "$EXCLUSION_REGEX" "$JQ"
        else
            local SHA="$(sha256sum < "$FILE" | cut -d ' ' -f 1)"
            local SIZE="$(stat --format=%s -- "$FILE")"
            echo "$SHA $SIZE $__WEESU_SOURCE_ID_BASE64__ $(echo -n "$FILE" | base64 -w0) $__WEESU_TIME__"
        fi
    done
}

scan_tree(){
    local THE_DIR="$1"
    local EXCLUSION_REGEX="$2"
    (
        cd "$THE_DIR"
        all_matching_dirs "$EXCLUSION_REGEX" \
            | all_matching_files "$EXCLUSION_REGEX" \
            | read_files "$EXCLUSION_REGEX"
    )
}

if [[ -n "${__WEESU_RECUR__+x}" ]]; then
    # This is the portion called by tar when enumerating the
    # elements of a tarball
    #
    # Tricky stuff here -- we want to read the input two or three
    # times (once to get the SHA, once to get the size, and possibly
    # a third time if it's a tarball, to enumerate the contents), but
    # in a streaming fashion; so make a couple pipes and copy to them
    # with tee.
    PIPE=$(mktemp -u)
    mkfifo $PIPE
    exec 3<>$PIPE
    rm $PIPE

    if [[ "$TAR_FILENAME" == *.tgz || "$TAR_FILENAME" == *.tar.gz ]]; then
        PIPE=$(mktemp -u)
        mkfifo $PIPE
        (
            __WEESU_PATH__="$__WEESU_PATH__$TAR_FILENAME//" tar --to-command="$0" -zx <$PIPE
        ) &
        PID=$!
    else
        PIPE=/dev/null
    fi
    SHA="$(tee >(wc -c >&3) $PIPE | sha256sum | cut -d ' ' -f 1)"
    if [[ $PIPE != "/dev/null" ]]; then rm $PIPE; fi
    read SIZE <&3
    exec 3>&-
    if [[ -n "${PID:-}" ]]; then wait $PID; fi
    echo "$SHA $SIZE $__WEESU_SOURCE_ID_BASE64__ $(echo -n "$__WEESU_PATH__$TAR_FILENAME" | base64 -w0) $__WEESU_TIME__"
    exit 0
fi

# Like uniq, but only considers the first three "columns";
# uniq seems incapable of doing this
uniq13(){
    CURRENT_K=""
    while read A B C MORE; do
        K="$A $B $C"
        if [[ "$CURRENT_K" != "$K" ]]; then
            echo "$K $MORE"
            CURRENT_K="$K"
        fi
    done
}

if [[ "$#" -eq 0 ]]; then
    print_usage_and_exit
elif [[ "$(jq --version)" != "jq-1.6" ]]; then
    echo "weesu requires JQ version 1.6!" >&2
    exit 42
fi

CMD="$1"; shift

case "$CMD" in
    "catalog")
        if [[ "$#" -lt 2 ]]; then
            print_usage_and_exit
        fi
        export __WEESU_SOURCE_ID_BASE64__="$(echo -n "$1" | base64 -w0)"
        export __WEESU_TIME__="$(date -u +"%Y-%m-%dT%H:%M:%S.%3NZ")"

        THE_DIR="$2"
        if [[ ! -d "$THE_DIR" ]]; then
            echo "$THE_DIR is not a directory!" >&2
            exit 1
        fi

        shift; shift
        if [[ "$#" -eq 2 && "$1" == "--exclude" ]]; then
            EXCLUSION_REGEX="$2"
            shift; shift
        else
            EXCLUSION_REGEX='^///$' # shouldn't match anything
        fi
        if [[ "$#" -ne 0 ]]; then
            print_usage_and_exit
        fi

        scan_tree "$THE_DIR" "$EXCLUSION_REGEX" | sort_and_rollup

        ;;
    "merge")
        if [[ "$#" -ne 2 ]]; then
            print_usage_and_exit
        fi
        FILE1="$1"
        FILE2="$2"
        cat <(unrollup < "$FILE1") <(unrollup < "$FILE2") | sort_and_rollup
        ;;
    "stale")
        if [[ "$#" -ne 0 ]]; then
            print_usage_and_exit
        fi
        JQ_FILTER='. as $rec
                   | .seen[]
                   | (.source_id | @base64) as $source64
                   | (.path | @base64) as $path64
                   | "\($source64) source_global null \(.at)",
                     "\($source64) blob \($rec.sha256) \(.at) \($path64)"'
        SOURCE_ID=""
        SOURCE_AT=""
        jq -rcMS "$JQ_FILTER" \
            | LC_ALL=C sort -k 1,3 -r \
            | uniq13 \
            | while read SOURCE_ID_64 LINE_TYPE X AT Y; do
                  case "$LINE_TYPE" in
                      "source_global")
                          SOURCE_ID="$(<<< "$SOURCE_ID_64" base64 -d)"
                          SOURCE_AT="$AT"
                      ;;
                      "blob")
                          BLOB_AT="$AT"
                          if [[ "$BLOB_AT" < "$SOURCE_AT" ]]; then
                              SHA="$X"
                              THE_PATH="$(<<< "$Y" base64 -d)"
                              echo "STALE BLOB (${SHA:0:10}) LAST SEEN IN $SOURCE_ID AT $BLOB_AT AT $THE_PATH, LATEST SOURCE MEASUREMENT AT $SOURCE_AT"
                          fi
                      ;;
                      *)
                          >&2 echo "ERROR: THIS IS IMPOSSIBLE: $(printf %q "$LINE_TYPE")"
                          exit 42
                      ;;
                  esac
        done
        ;;
    "histogram")
        if [[ "$#" -ne 0 ]]; then
            print_usage_and_exit
        fi
        JQ_FILTER='.seen | map(.source_id) | unique'
        jq -cMS "$JQ_FILTER" | sort | uniq -c
        ;;
    *)
        print_usage_and_exit
        ;;
esac
