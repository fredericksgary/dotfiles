#!/usr/bin/env bash

# A script for creating and managing records of where
# (presumably large) files are.
#
# Can read a directory and create a JSON file describing
# its contents (including recursing into tarballs and
# zip files), merge JSON files together, and query
# and edit JSON files

set -Ceou pipefail

print_usage_and_exit(){
    cat >&2 <<EOF
    Usage:

    weesu catalog <source-id> <dirname>
      - writes a json file to stdout
    weesu merge <file1> <file2>
      - writes a json file to stdout
    weesu stale
      - reads json records from stdin and prints
        a summary of objects that were previously
        seen at a source but not in the latest
        viewing of that source
EOF
    exit 1
}

write_output_line(){
    SHA="$1"
    SIZE="$2"
    THE_PATH="$3"
    OBS="$(jq -cnM \
              --arg source_id "$__WEESU_SOURCE_ID__" \
              --arg at "$__WEESU_TIME__" \
              --arg path "$THE_PATH" \
              '.source_id = $source_id | .at = $at | .path = $path'
           )"
    jq -cnMS \
       --arg sha "$SHA" \
       --argjson size "$SIZE" \
       --argjson obs "$OBS" \
       '.sha256 = $sha | .size = $size | .seen = [$obs]'
}

scan_dir(){
    local BASE_PATH="$1"
    local THE_DIR="$2"
    (
        cd "$THE_DIR"
        # Can add a -a flag to opt-in to hidden files at some point
        for FILE in *; do
            local THE_PATH="$BASE_PATH$FILE"
            if [[ -f "$FILE" ]]; then
                if [[ -r "$FILE" ]]; then
                    local SHA="$(sha256sum < "$FILE" | cut -d ' ' -f 1)"
                    local SIZE="$(stat --format=%s -- "$FILE")"
                    write_output_line "$SHA" "$SIZE" "$THE_PATH"
                    # I'd like to get .zip files too, but I don't think
                    # the zip program has an easy enumeration option like
                    # tar does
                    if [[ "$FILE" == *.tgz || "$FILE" == *.tar.gz ]]; then
                        __WEESU_RECUR__=t \
                                       __WEESU_PATH__="$BASE_PATH$FILE//" \
                                       tar --to-command="$0" -zxf "$FILE"
                    fi
                else
                    >&2 echo "WARNING: skipping $(printf %q "$FILE"), which is not readable"
                fi
            elif [[ -d "$FILE" ]]; then
                if [[ -r "$FILE" && -x "$FILE" ]]; then
                    scan_dir "$BASE_PATH$FILE/" "$FILE"
                else
                    >&2 echo "WARNING: skipping directory $(printf %q "$FILE") due to insufficient permissions"
                fi
            elif [[ -e "$FILE" ]]; then
                >&2 echo "WARNING: skipping $(printf %q "$FILE"), which is not a file or directory"
            fi
        done
    )
}

if [[ -n "${__WEESU_RECUR__+x}" ]]; then
    # This is the portion called by tar when enumerating the
    # elements of a tarball
    #
    # Tricky stuff here -- we want to read the input two or three
    # times (once to get the SHA, once to get the size, and possibly
    # a third time if it's a tarball, to enumerate the contents), but
    # in a streaming fashion; so make a couple pipes and copy to them
    # with tee.
    PIPE=$(mktemp -u)
    mkfifo $PIPE
    exec 3<>$PIPE
    rm $PIPE

    if [[ "$TAR_FILENAME" == *.tgz || "$TAR_FILENAME" == *.tar.gz ]]; then
        PIPE=$(mktemp -u)
        mkfifo $PIPE
        (
            __WEESU_PATH__="$__WEESU_PATH__$TAR_FILENAME//" tar --to-command="$0" -zx <$PIPE
        ) &
        PID=$!
    else
        PIPE=/dev/null
    fi
    SHA="$(tee >(wc -c >&3) $PIPE | sha256sum | cut -d ' ' -f 1)"
    if [[ $PIPE != "/dev/null" ]]; then rm $PIPE; fi
    read SIZE <&3
    exec 3>&-
    if [[ -n "${PID:-}" ]]; then wait $PID; fi
    write_output_line "$SHA" "$SIZE" "$__WEESU_PATH__$TAR_FILENAME"
    exit 0
elif [[ "$#" -eq 0 ]]; then
    print_usage_and_exit
fi

merge_seens(){
    FIRST_TIME=1
    # How about put the key and the rest of it on different lines, and
    # do a fancier while true loop
    jq -cMS '[[.source_id, .path],.at,.]' \
        | sort \
        | jq -cMS '.[0],.[2]' \
        | while true; do
              if [[ -n $FIRST_TIME ]]; then
                  read -r KEY1 || break
                  read -r VAL1
                  FIRST_TIME=""
              fi
              if read -r KEY2; then
                  read -r VAL2
                  if [[ "$KEY1" != "$KEY2" ]]; then
                      echo "$VAL1"
                  fi
                  KEY1="$KEY2"
                  VAL1="$VAL2"
              else
                  echo "$VAL1"
                  break
              fi
          done \
        | jq -cMSs .
}

merge2(){
    local JSON1="$1"
    local JSON2="$2"
    local JSON1NOSEEN="$(<<< "$JSON1" jq -cMS 'del(.seen)')"
    local JSON2NOSEEN="$(<<< "$JSON2" jq -cMS 'del(.seen)')"
    # sanity check
    if [[ "$JSON1NOSEEN" == "$JSON2NOSEEN" ]]; then
        # it'd also be nice to check that there are no redundant
        # seens, but that sounds harder; only relevant for
        # real merging
        SEENS="$(jq -cnMS \
                 --argjson json1 "$JSON1" \
                 --argjson json2 "$JSON2" \
                 '$json1.seen + $json2.seen | .[]' \
                 | merge_seens)"
        <<< "$JSON1" jq -cMS --argjson seens "$SEENS" '.seen=$seens'
    else
        echo "IMPOSSIBLE ERROR" >&2
        exit 42
    fi
}

# Prints one object per line with the sha256 key first
sort_and_normalize(){
    # rename the sha256 key so it sorts to the front
    jq -cMS '[.sha256,(._sha256 = .sha256 | del(.sha256))]' \
        | sort \
        | jq -cMS '.[1]' \
        | sed s/_sha/sha/
}

# I think I want to rename the sha thing here
merge_lines(){
    MERGER={}
    # start by renaming the sha256 key so it sorts to the
    # front
    sort_and_normalize \
        | cat - <(echo LAST_LINE) \
        | while read -r NEXT_LINE; do
              if [[ "$NEXT_LINE" == LAST_LINE ]]; then
                  if [[ "$MERGER" != "{}" ]]; then
                      echo "$MERGER"
                  fi
                  break;
              fi
              SHA1="$(<<< "$MERGER" jq -cMS .sha256)"
              SHA2="$(<<< "$NEXT_LINE" jq -cMS .sha256)"
              if [[ "$SHA1" == "$SHA2" ]]; then
                  MERGER="$(merge2 "$MERGER" "$NEXT_LINE")"
              else
                  if [[ "$MERGER" != "{}" ]]; then
                      echo "$MERGER"
                  fi
                  MERGER="$NEXT_LINE"
              fi
          done \
        | sort_and_normalize
}

case "$1" in
    "catalog")
        if [[ "$#" -ne 3 ]]; then
            print_usage_and_exit
        fi
        export __WEESU_SOURCE_ID__="$2"
        export __WEESU_TIME__="$(date -u +"%Y-%m-%dT%H:%M:%S.%3NZ")"

        THE_DIR="$3"
        if [[ ! -d "$THE_DIR" ]]; then
            echo "$THE_DIR is not a directory!" >&2
            exit 1
        fi

        scan_dir "${__WEESU_PATH__:-}" "$THE_DIR" | merge_lines

        ;;
    "merge")
        FILE1="$2"
        FILE2="$3"
        sort -m \
             <(sort_and_normalize < "$FILE1") \
             <(sort_and_normalize < "$FILE2") \
            | merge_lines
        ;;
    "stale")
        # we first want: a mapping from source IDs to the latest timestamp
        # associated with them
        #
        # then for each SHA, we want to know its latest timestamp for
        # each source, and compare that with the globally latest timestamp
        # for each source
        # could sort -u help with this? "output only the first of an equal run"
        # I think the only problem is that source_ids can have whitespace (or any
        # given practical delimeter!); I
        # wish there were a way to hex encode them OH HEY THERE IS BASE64!!!
        #
        #
        # Okay okay what if we output things so that we arrange for info about
        # each source to be grouped together; then we dupe information so that
        # first we get a generic record of all the timestamps for the source,
        # with the latest one sorted to the top, and then underneath that we have
        # information for each blob, sorted so that we get the latest timestamp
        # for that THIS'LL BE GREAT
        JQ_FILTER='. as $rec
                   | .seen[]
                   | [(.source_id | @base64),"source_global",null,.at],
                     [(.source_id | @base64),"blob",$rec.sha256,.at,.path]'
        SOURCE_ID=""
        SOURCE_AT=""
        jq -cMS "$JQ_FILTER" \
            | LC_ALL=C sort -u -t , -k 1,3 -r \
            | while read LINE; do
                  LINE_TYPE="$(<<< "$LINE" cut -d , -f 2)"
                  case "${LINE_TYPE:1:-1}" in
                      "source_global")
                          SOURCE_ID_HEX_JSON="$(<<< "$LINE" cut -d , -f 1)"
                          SOURCE_ID="$(echo "${SOURCE_ID_HEX_JSON:2:-1}" | base64 -d)"
                          SOURCE_AT="$(<<< "$LINE" cut -d , -f 4)"
                          SOURCE_AT="${SOURCE_AT:1:-2}"
                      ;;
                      "blob")
                          BLOB_AT="$(<<< "$LINE" cut -d , -f 4)"
                          BLOB_AT="${BLOB_AT:1:-1}"
                          if [[ "$BLOB_AT" < "$SOURCE_AT" ]]; then
                              SHA="$(<<< "$LINE" cut -d , -f 3)"
                              THE_PATH="$(<<< "$LINE" cut -d , -f 5-)"
                              echo "STALE BLOB (${SHA:1:10}) LAST SEEN IN $SOURCE_ID AT $BLOB_AT AT ${THE_PATH:1:-2}, LATEST SOURCE MEASUREMENT AT $SOURCE_AT"
                          fi
                      ;;
                      *)
                          >&2 echo "ERROR: THIS IS IMPOSSIBLE: $(printf %q "$LINE_TYPE")"
                          exit 42
                      ;;
                  esac
        done
        ;;
    *)
        print_usage_and_exit
        ;;
esac
