#!/usr/bin/env bash

# A script for creating and managing records of where
# (presumably large) files are.
#
# Can read a directory and create a JSON file describing
# its contents (including recursing into tarballs and
# zip files), merge JSON files together, and query
# and edit JSON files

set -Ceou pipefail

print_usage_and_exit(){
    cat >&2 <<EOF
    Usage:

    weesu catalog <source-id> <dirname>
      - writes a json file to stdout
    weesu merge <file1> <file2>
      - writes a json file to stdout
    weesu stale
      - reads json records from stdin and prints
        a summary of blobs that were previously
        seen at a source but not in the latest
        viewing of that source
    weesu histogram
      - reads json records from stdin and prints
        a count of what combinations of sources
        blobs appear in
EOF
    exit 1
}

write_output_line(){
    SHA="$1"
    SIZE="$2"
    THE_PATH="$3"
    OBS="$(jq -cnM \
              --arg source_id "$__WEESU_SOURCE_ID__" \
              --arg at "$__WEESU_TIME__" \
              --arg path "$THE_PATH" \
              '.source_id = $source_id | .at = $at | .path = $path'
           )"
    jq -cnMS \
       --arg sha "$SHA" \
       --argjson size "$SIZE" \
       --argjson obs "$OBS" \
       '.sha256 = $sha | .size = $size | .seen = [$obs]'
}

scan_dir(){
    local BASE_PATH="$1"
    local THE_DIR="$2"
    (
        cd "$THE_DIR"
        # Can add a -a flag to opt-in to hidden files at some point
        for FILE in *; do
            local THE_PATH="$BASE_PATH$FILE"
            if [[ -f "$FILE" ]]; then
                if [[ -r "$FILE" ]]; then
                    local SHA="$(sha256sum < "$FILE" | cut -d ' ' -f 1)"
                    local SIZE="$(stat --format=%s -- "$FILE")"
                    write_output_line "$SHA" "$SIZE" "$THE_PATH"
                    # I'd like to get .zip files too, but I don't think
                    # the zip program has an easy enumeration option like
                    # tar does
                    if [[ "$FILE" == *.tgz || "$FILE" == *.tar.gz ]]; then
                        __WEESU_RECUR__=t \
                                       __WEESU_PATH__="$BASE_PATH$FILE//" \
                                       tar --to-command="$0" -zxf "$FILE"
                    fi
                else
                    >&2 echo "WARNING: skipping $(printf %q "$FILE"), which is not readable"
                fi
            elif [[ -d "$FILE" ]]; then
                if [[ -r "$FILE" && -x "$FILE" ]]; then
                    scan_dir "$BASE_PATH$FILE/" "$FILE"
                else
                    >&2 echo "WARNING: skipping directory $(printf %q "$FILE") due to insufficient permissions"
                fi
            elif [[ -e "$FILE" ]]; then
                >&2 echo "WARNING: skipping $(printf %q "$FILE"), which is not a file or directory"
            fi
        done
    )
}

if [[ -n "${__WEESU_RECUR__+x}" ]]; then
    # This is the portion called by tar when enumerating the
    # elements of a tarball
    #
    # Tricky stuff here -- we want to read the input two or three
    # times (once to get the SHA, once to get the size, and possibly
    # a third time if it's a tarball, to enumerate the contents), but
    # in a streaming fashion; so make a couple pipes and copy to them
    # with tee.
    PIPE=$(mktemp -u)
    mkfifo $PIPE
    exec 3<>$PIPE
    rm $PIPE

    if [[ "$TAR_FILENAME" == *.tgz || "$TAR_FILENAME" == *.tar.gz ]]; then
        PIPE=$(mktemp -u)
        mkfifo $PIPE
        (
            __WEESU_PATH__="$__WEESU_PATH__$TAR_FILENAME//" tar --to-command="$0" -zx <$PIPE
        ) &
        PID=$!
    else
        PIPE=/dev/null
    fi
    SHA="$(tee >(wc -c >&3) $PIPE | sha256sum | cut -d ' ' -f 1)"
    if [[ $PIPE != "/dev/null" ]]; then rm $PIPE; fi
    read SIZE <&3
    exec 3>&-
    if [[ -n "${PID:-}" ]]; then wait $PID; fi
    write_output_line "$SHA" "$SIZE" "$__WEESU_PATH__$TAR_FILENAME"
    exit 0
fi

merge_seens(){
    FIRST_TIME=1
    # How about put the key and the rest of it on different lines, and
    # do a fancier while true loop
    jq -cMS '[[.source_id, .path],.at,.]' \
        | sort \
        | jq -cMS '.[0],.[2]' \
        | while true; do
              if [[ -n $FIRST_TIME ]]; then
                  read -r KEY1 || break
                  read -r VAL1
                  FIRST_TIME=""
              fi
              if read -r KEY2; then
                  read -r VAL2
                  if [[ "$KEY1" != "$KEY2" ]]; then
                      echo "$VAL1"
                  fi
                  KEY1="$KEY2"
                  VAL1="$VAL2"
              else
                  echo "$VAL1"
                  break
              fi
          done \
        | jq -cMSs .
}

merge2(){
    local JSON1="$1"
    local JSON2="$2"
    local JSON1NOSEEN="$(<<< "$JSON1" jq -cMS 'del(.seen)')"
    local JSON2NOSEEN="$(<<< "$JSON2" jq -cMS 'del(.seen)')"
    # sanity check
    if [[ "$JSON1NOSEEN" == "$JSON2NOSEEN" ]]; then
        # it'd also be nice to check that there are no redundant
        # seens, but that sounds harder; only relevant for
        # real merging
        SEENS="$(jq -cnMS \
                 --argjson json1 "$JSON1" \
                 --argjson json2 "$JSON2" \
                 '$json1.seen + $json2.seen | .[]' \
                 | merge_seens)"
        <<< "$JSON1" jq -cMS --argjson seens "$SEENS" '.seen=$seens'
    else
        echo "IMPOSSIBLE ERROR" >&2
        exit 42
    fi
}

# Prints one object per line with the sha256 key first
sort_and_normalize(){
    # rename the sha256 key so it sorts to the front
    jq -cMS '[.sha256,(._sha256 = .sha256 | del(.sha256))]' \
        | sort \
        | jq -cMS '.[1]' \
        | sed s/_sha/sha/
}

# I think I want to rename the sha thing here
merge_lines(){
    MERGER={}
    # start by renaming the sha256 key so it sorts to the
    # front
    sort_and_normalize \
        | cat - <(echo LAST_LINE) \
        | while read -r NEXT_LINE; do
              if [[ "$NEXT_LINE" == LAST_LINE ]]; then
                  if [[ "$MERGER" != "{}" ]]; then
                      echo "$MERGER"
                  fi
                  break;
              fi
              SHA1="$(<<< "$MERGER" jq -cMS .sha256)"
              SHA2="$(<<< "$NEXT_LINE" jq -cMS .sha256)"
              if [[ "$SHA1" == "$SHA2" ]]; then
                  MERGER="$(merge2 "$MERGER" "$NEXT_LINE")"
              else
                  if [[ "$MERGER" != "{}" ]]; then
                      echo "$MERGER"
                  fi
                  MERGER="$NEXT_LINE"
              fi
          done \
        | sort_and_normalize
}

# Like uniq, but only considers the first three "columns";
# uniq seems incapable of doing this
uniq13(){
    CURRENT_K=""
    while read A B C MORE; do
        K="$A $B $C"
        if [[ "$CURRENT_K" != "$K" ]]; then
            echo "$K $MORE"
            CURRENT_K="$K"
        fi
    done
}

if [[ "$#" -eq 0 ]]; then
    print_usage_and_exit
fi

CMD="$1"; shift

case "$CMD" in
    "catalog")
        if [[ "$#" -ne 2 ]]; then
            print_usage_and_exit
        fi
        export __WEESU_SOURCE_ID__="$1"
        export __WEESU_TIME__="$(date -u +"%Y-%m-%dT%H:%M:%S.%3NZ")"

        THE_DIR="$2"
        if [[ ! -d "$THE_DIR" ]]; then
            echo "$THE_DIR is not a directory!" >&2
            exit 1
        fi

        scan_dir "${__WEESU_PATH__:-}" "$THE_DIR" | merge_lines

        ;;
    "merge")
        if [[ "$#" -ne 2 ]]; then
            print_usage_and_exit
        fi
        FILE1="$1"
        FILE2="$2"
        sort -m \
             <(sort_and_normalize < "$FILE1") \
             <(sort_and_normalize < "$FILE2") \
            | merge_lines
        ;;
    "stale")
        if [[ "$#" -ne 0 ]]; then
            print_usage_and_exit
        fi
        JQ_FILTER='. as $rec
                   | .seen[]
                   | (.source_id | @base64) as $source64
                   | (.path | @base64) as $path64
                   | "\($source64) source_global null \(.at)",
                     "\($source64) blob \($rec.sha256) \(.at) \($path64)"'
        SOURCE_ID=""
        SOURCE_AT=""
        jq -rcMS "$JQ_FILTER" \
            | LC_ALL=C sort -k 1,3 -r \
            | tee /tmp/phase1.txt \
            | uniq13 \
            | tee /tmp/phase2.txt \
            | while read SOURCE_ID_64 LINE_TYPE X AT Y; do
                  case "$LINE_TYPE" in
                      "source_global")
                          SOURCE_ID="$(<<< "$SOURCE_ID_64" base64 -d)"
                          SOURCE_AT="$AT"
                      ;;
                      "blob")
                          BLOB_AT="$AT"
                          if [[ "$BLOB_AT" < "$SOURCE_AT" ]]; then
                              SHA="$X"
                              THE_PATH="$(<<< "$Y" base64 -d)"
                              echo "STALE BLOB (${SHA:0:10}) LAST SEEN IN $SOURCE_ID AT $BLOB_AT AT $THE_PATH, LATEST SOURCE MEASUREMENT AT $SOURCE_AT"
                          fi
                      ;;
                      *)
                          >&2 echo "ERROR: THIS IS IMPOSSIBLE: $(printf %q "$LINE_TYPE")"
                          exit 42
                      ;;
                  esac
        done
        ;;
    "histogram")
        if [[ "$#" -ne 0 ]]; then
            print_usage_and_exit
        fi
        JQ_FILTER='.seen | map(.source_id) | unique'
        jq -cMS "$JQ_FILTER" | sort | uniq -c
        ;;
    *)
        print_usage_and_exit
        ;;
esac
